a3.sources = r3
a3.channels = c3
a3.sinks = k3

a3.sources.r3.type = org.apache.flume.source.kafka.KafkaSource
a3.sources.r3.batchSize = 5000
a3.sources.r3.batchDurationMillis = 2000
a3.sources.r3.kafka.bootstrap.servers = issac:9092
a3.sources.r3.kafka.topics = cart_info,comment_info,coupon_use,favor_info,order_detail_activity,order_detail_coupon,order_detail,order_info,order_refund_info,order_status_log,payment_info,refund_payment,user_info
a3.sources.r3.kafka.consumer.group.id = flume
a3.sources.r3.setTopicHeader = true
a3.sources.r3.topicHeader = topic
a3.sources.r3.interceptors = i1
a3.sources.r3.interceptors.i1.type = interceptor.TimeInterceptor$Builder
TimeInterceptor$Builder.class

a3.channels.c3.type = file
a3.channels.c3.checkpointDir = /home/issac/coding/java/study/hive/script/deploy/flume/db-cp/
a3.channels.c3.dataDirs = /home/issac/coding/java/study/hive/script/deploy/flume/db-cache/
a3.channels.c3.maxFileSize = 2146435071
a3.channels.c3.capacity = 1123456
a3.channels.c3.keep-alive = 6

## sink3
a3.sinks.k3.type = hdfs
a3.sinks.k3.hdfs.path = /warehouse/origin/db/%{topic}_inc/2021-08-15
a3.sinks.k3.hdfs.filePrefix = db-
a3.sinks.k3.hdfs.round = false

# 4.1 控制生成的小文件
a3.sinks.k3.hdfs.rollInterval = 360
a3.sinks.k3.hdfs.rollSize = 67108864
a3.sinks.k3.hdfs.rollCount = 0


a3.sinks.k3.hdfs.fileType = CompressedStream
a3.sinks.k3.hdfs.codeC = gzip

## 拼装
a3.sources.r3.channels = c3
a3.sinks.k3.channel= c3
