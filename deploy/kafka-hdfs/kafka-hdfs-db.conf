# 1. 为各组件进行命名
a3.sources = r3
a3.channels = c3
a3.sinks = k3
    
    
# 2. 配置 source
a3.sources.r3.type = org.apache.flume.source.kafka.KafkaSource
a3.sources.r3.batchSize = 5000
a3.sources.r3.batchDurationMillis = 2000
a3.sources.r3.kafka.bootstrap.servers = issac:9092
a3.sources.r3.kafka.topics = cart_info,comment_info,coupon_use,favor_info,order_detail_activity,order_detail_coupon,order_detail,order_info,order_refund_info,order_status_log,payment_info,refund_payment,user_info
a3.sources.r3.kafka.consumer.group.id = flume
a3.sources.r3.setTopicHeader = true
a3.sources.r3.topicHeader = topic
    
# 2.1 拦截器
a3.sources.r3.interceptors = i1
a3.sources.r3.interceptors.i1.type = interceptor.TimeInterceptor$Builder
TimeInterceptor$Builder.class
    
    
# 3. 配置 channel
a3.channels.c3.type = file
a3.channels.c3.checkpointDir = /offline-data-warehouse/kafka-hdfs/check-point/db/
a3.channels.c3.dataDirs = /offline-data-warehouse/kafka-hdfs/data/db/
a3.channels.c3.maxFileSize = 2146435071
a3.channels.c3.capacity = 1123456
a3.channels.c3.keep-alive = 6
    
    
# 4. 配置 sink
a3.sinks.k3.type = hdfs
a3.sinks.k3.hdfs.path = /warehouse/db/%{topic}_inc/2021-08-15
a3.sinks.k3.hdfs.filePrefix = db-
a3.sinks.k3.hdfs.round = false

# 4.1 控制生成的小文件
a3.sinks.k3.hdfs.rollInterval = 360
a3.sinks.k3.hdfs.rollSize = 67108864
a3.sinks.k3.hdfs.rollCount = 0

# 4.2 配置 HDFS 压缩
a3.sinks.k3.hdfs.fileType = CompressedStream
a3.sinks.k3.hdfs.codeC = gzip
    
    
# 5. 进行拼接组件，绑定 source 和 channel 以及 sink 和 channel 的关系
a3.sources.r3.channels = c3
a3.sinks.k3.channel= c3
