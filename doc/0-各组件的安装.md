# <center>离线数仓中各组件安装</center>

## 1. linux 系统基本配置

### 1.1 linux 系统说明

|        |     master      |     slaver1     |     slaver2     |     slaver3     |
|:------:|:---------------:|:---------------:|:---------------:|:---------------:|
|  CPU   |      4C/8T      |      4C/8T      |      4C/8T      |      4C/8T      |
|  内存  |  16GB/3200MHz   |  16GB/3200MHz   |  16GB/3200MHz   |  16GB/3200MHz   |
|  硬盘  |    HDD 40GB     |    HDD 40GB     |    HDD 40GB     |    HDD 40GB     |
|  网卡  |    1000Mbps     |    1000Mbps     |    1000Mbps     |    1000Mbps     |
|   IP   | 192.168.100.100 | 192.168.100.111 | 192.168.100.122 | 192.168.100.133 |
|  系统  | Rocky Linux 9.1 | Rocky Linux 9.1 | Rocky Linux 9.1 | Rocky Linux 9.1 |


### 1.2 修改 dnf 为国内的 阿里镜像源

```bash 
    # 下载
    sed -e 's|^mirrorlist=|#mirrorlist=|g' \
        -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g' \
        -i.bak /etc/yum.repos.d/[Rr]ocky-*.repo
    
    dnf clean all
    dnf makecache
    dnf update
    dnf upgrade
```

### 1.3 修改主机名称

```bash
    hostname                                               # 查看当前系统的主机名
    hostname master                                        # 临时修改主机名为 master，会话关闭失效
    hostnamectl set-hostname master                        # 永久修改主机名为 master（重启生效）
    vim /etc/hostname                                      # 永久修改主机名为 master（重启生效）
```

### 1.4 修改 hosts 映射

```bash
    # 方法一：vim 编辑器进行修改
    vim /etc/hosts                                         # 使用 vim 编辑器添加如下内容
        192.168.100.10      master
    
    # 方法二：使用重定向追加模式
    echo "192.168.100.100      master"  >> /etc/hosts      # master
    echo "192.168.100.111      slaver1" >> /etc/hosts      # slaver1
    echo "192.168.100.122      slaver2" >> /etc/hosts      # slaver2
    echo "192.168.100.133      slaver3" >> /etc/hosts      # slaver3
    
    # 以下内容适量添加
    echo "127.0.0.1            unix"    >> /etc/hosts      # unix
    echo "127.0.0.1            linux"   >> /etc/hosts      # linux
    echo "127.0.0.1            rocky"   >> /etc/hosts      # rocky
    echo "127.0.0.1            elastic" >> /etc/hosts      # elastic
```


### 1.5 关闭防火墙

```bash
    # start：开启防火墙；stop：关闭防火墙；status：查看状态；enable：开机自启；disable：关闭开机自启
    systemctl status  firewalld.service                    # 查看防火墙状态，或者：firewall-cmd --state
    systemctl stop    firewalld.service                    # 关闭防火墙
    systemctl disable firewalld.service                    # 关闭防火墙开机自启
    
    # 将如下 ip 添加到防火墙
    firewall-cmd --permanent --add-source=192.168.100.100  # 添加到防火墙白名单
    firewall-cmd --permanent --add-source=192.168.100.111  # 添加到防火墙白名单
    firewall-cmd --permanent --add-source=192.168.100.122  # 添加到防火墙白名单
    firewall-cmd --permanent --add-source=192.168.100.133  # 添加到防火墙白名单
```


### 1.6 关闭 selinux

```bash
    sudo apt install policycoreutils                       # ubuntu 安装策略包
    sudo yum install policycoreutils                       # redhat 安装策略包
    sestatus                                               # 检查系统 SELinux 状态
    setenforce 0                                           # 临时禁用 SELinux，或者：setenforce Permissive
    vim /etc/sysconfig/selinux                             # 编辑 SELinux 配置文件
        SELinux=disabled                                   # 注释 SELinux=enforcing，需要重启系统
    sestatus                                               # 检查系统 SELinux 状态
```

### 1.7 修改打开文件限制：etc/security/limits.conf

```bash
    *    soft    nproc      65536
    *    hard    nproc      65536
    *    soft    nofile     65536
    *    hard    nofile     65536
    *    soft    stack      20480
    *    hard    stack      20480
    
    *    soft    memlock    134217728
    *    hard    memlock    134217728
    *    soft    data       unlimited
    *    hard    data       unlimited
```

### 1.8 设置虚拟内存

```bash
    swapon -s                                              # 查看当前 swap 的使用情况
    cat /proc/swaps                                        # 查看当前 swap 的使用情况
    swapoff /swap/swapfile                                 # 关闭相应的 swap_disk_name
    rm /swap/swapfile                                      # 删除 swapfile 文件
    /swap/swapfile swap swap defaults 0 0                  # vim 编辑器打开 /etc/fstab，删除此内容
    
    cd /tmp/                                               # 进入根路径
    dd if=/dev/zero of=/tmp/swap bs=1M count=16384         # 创建虚拟内存文件
    chmod 600 /tmp/swap                                    # 给文件添加授权
    du -sh /tmp/swap                                       # 查看 swap 文件
    mkswap /tmp/swap                                       # 将目标设置为 swap 分区文件
    swapon /tmp/swap                                       # 激活 swap 区，并立即启用交换区文件
    free -m                                                # 查看Swap 分区
    sysctl vm.swappiness=10                                # 临时修改启用虚拟内存时剩余的内存大小
    vim /etc/fstab                                         # vim 编辑器打开 /etc/fstab，添加此如下内容
        /tmp/swap swap swap defaults 0 0
    vim /etc/sysctl.conf                                   # 永久修改启用虚拟内存时剩余的内存大小，添加此如下内容
        vm.swappiness=25
```


### 1.9 添加管理员帐号

```bash
    useradd -m issac                                       # 添加 issac 用户
    chmod u+w /etc/sudoers                                 # 添加可编辑权限
    vim /etc/sudoers                                       # 给 issac 添加管理员权限，添加如下内容
        issac   ALL=(ALL:ALL)   ALL
    chmod u-w /etc/sudoers                                 # 取消可编辑权限
    root                                                   # 重启服务器，并使用 issac 用户登录：shutdown -r now
```

### 1.10 安装必要的软件包

```bash
    # redhat 系列
    sudo yum install -y epel-release                       # 安装 红帽系 的操作系统提供额外的软件包
    sudo yum install -y git                                # 安装 git 用于编译
    sudo yum install -y lrzsz                              # 安装 lrzsz 可用于文件传输
    sudo yum install -y htop                               # 监控服务器
    sudo yum install -y curl-devel expat-devel openssl-devel gcc gcc-c++ kernel-devel pcsc-lite-libs elfutils-libelf-devel make    # 安装编译器
```

### 1.11 配置免密登录

```bash
    # 安装 ssh 
    sudo apt-get install openssh-server                                        # ubuntu，安装 ssh
    sudo yum install openssh-server                                            # redhat，安装 ssh
    
    # 配置免密登录
    ssh-keygen -t rsa                                                          # 每台机器生成秘钥（连续回车 3 次）
    
    # 传输公钥
    ssh-copy-id issac@master                                                   # 在每个 slaver节点上，将公钥复制到 master
    scp ~/.ssh/id_rsa.pub issac@master:~/.ssh/id_rsa.pub.slaver*               # 在每个 slaver 节点上，将各自的 id_rsa.pub 发给 master 节点
    
    # 合成公钥，并分发
    cat ~/.ssh/id_rsa.pub* >> ~/.ssh/authorized_keys                           # 在 master 上，将所有公钥加到用于认证的公钥文件 authorized_keys 中
    scp ~/.ssh/authorized_keys issac@slaver*:~/.ssh/                           # 将 master 上，将文件 authorized_keys 分发给每台 slaver
    
    # 修改权限
    chmod 600 ~/.ssh/authorized_keys                                           # 在所有节点上，修改每个主机 authorized_keys 的权限
    
    # 验证免密登录
    ssh slaver*                                                                # 免密登录到其它机器
```

<br/>

<br/>

## 2. 各个服务器的软件安装规划

<center>集群服务器规划</center>

|     服务名称     |  版本号  |      子服务       | master | slaver1 | slaver2 | slaver3 |                              说明                              |
|:----------------:|:--------:|:-----------------:|:------:|:-------:|:-------:|:-------:|:--------------------------------------------------------------:|
|       java       | 1.8.321  |       Java        |   √   |   √    |   √    |   √    |                                                                |
|      scala       | 2.12.17  |       Scala       |   √   |   √    |   √    |   √    |                                                                |
|      mysql       |  8.0.28  |       Mysql       |   √   |         |         |         |                                                                |
|                  |          |      NameNode     |   √   |         |         |         |                                                                |
|                  |  3.2.4   | SecondaryNameNode |   √   |         |         |         |                                                                |
|      hadoop      |          |     DataNode      |        |   √    |   √    |   √    |                                                                |
|                  |          |  ResourceManager  |   √   |         |         |         |                                                                |
|                  |          |    NodeManager    |        |   √    |   √    |   √    |                                                                |
|      spark       |  3.2.3   |   Spark on Yarn   |   √   |   √    |   √    |   √    |          需要编译源码，解决与 hadoop-3.2.4 的兼容问题          |
|      hbase       |  2.4.16  |      HMaster      |   √   |         |         |         |                                                                |
|                  |          |   HRegionServer   |        |   √    |   √    |   √    |                                                                |
|       hive       |  3.1.3   |   Hive on Spark   |   √   |         |         |         |  需要编译源码，解决与 hadoop-3.2.4 和 Spark-3.2.3 的兼容问题   |
|    zookeeper     |  3.6.4   |     Zookeeper     |        |   √    |   √    |   √    |                                                                |
|      kafka       |  3.2.3   |       Kafka       |        |   √    |   √    |   √    |                                                                |
|      mysql       |  8.0.28  |       Mysql       |   √   |         |         |         |                                                                |
|      flume       |  1.11.0  |       Flume       |   √   |   √    |   √    |   √    |               master 消费 Kafka，slaver 采集日志               |
|     maxwell      |  1.29.2  |      Maxwell      |        |   √    |   √    |   √    |                           同步 Mysql                           |
| DolphinScheduler |  3.1.3   |   MasterServer    |        |   √    |         |         |                                                                |
|                  |          |   WorkerServer    |        |         |   √    |   √    |                                                                |
|      datax       |  2022.9  |       DataX       |   √   |         |         |         |            需要替换 Mysql 的驱动 jar，以支持 8.0.x             |
|      presto      |          |    Coordinator    |        |   √    |         |         |                                                                |
|                  |          |      Worker       |        |         |   √    |   √    |                                                                |
|      druid       |          |       Druid       |        |   √    |   √    |   √    |                                                                |
|      kylin       |          |       Kylin       |   √   |         |         |         |                                                                |
|     Superset     |          |     Superset      |   √   |         |         |         |                                                                |
|      atlas       |          |       Atlas       |   √   |         |         |         |                                                                |
|      solr        |          |        solr       |        |   √    |   √    |   √    |                                                                |


<br/>

<br/>

## 3. 安装所需的编程语言

### 3.1 安装 JDK 并配置环境变量

#### 3.1.1 卸载系统自带的 open-jdk

```bash
    rpm -qa | grep java                                                        # 查看安装的 java，或者： yum list installed |grep java 
    rpm -qa | grep jdk                                                         # 查看安装的 jdk， 或者： yum list installed |grep jdk
    rpm -e --nodeps java-*                                                     # 卸载 java-*，    或者： yum -y remove java-*
    rpm -e --nodeps jdk-*                                                      # 卸载 jdk-*，     或者： yum -y remove jdk-*
```

#### 3.1.2 JDK 下载

  从 [**Oracle 官网**](https://www.oracle.com/java/technologies/downloads/#java8) 下载 [**JDK-1.8**](https://download.oracle.com/otn/java/jdk/8u361-b09/0ae14417abb444ebb02b9815e2103550/jdk-8u361-linux-x64.tar.gz) 到本地

#### 3.1.3 解压安装

```bash
    tar -zxvf jdk-8u361-linux-x64.tar.gz -C /opt/java/                         # 解压下载的 jdk-1.8 压缩包
    cd /opt/java/                                                              # 切换到解压目录
    mv jdk1.8.0_361/ jdk-08/                                                   # 修改目录名称
```

#### 3.1.4 配置环境变量

```bash
    # 切换 root 账户，配置系统的环境变量
    su - root                                                                  # 切换到 root 账户，或者使用 sudo 
    
    # 使用 vim 编辑器修改系统配置文件
    vim /etc/profile                                                           # 或使用：sudo vim /etc/profile 
    
    # 添加如下内容：
        # ====================================== JDK-1.8.351 ====================================== #
        export JAVA_HOME=/opt/java/jdk-08
        export JRE_HOME=${JAVA_HOME}/jre
        export CLASSPATH=.:${CLASSPATH}:${JAVA_HOME}/lib:${JRE_HOME}/lib
        export PATH=${PATH}:${JAVA_HOME}/bin:${JRE_HOME}/bin
    
    # 使系统变量生效
    source /etc/profile                                                        # 或者使用： . /etc/profile
```

#### 3.1.5 测试安装

```bash
    # 刷新环境变量
    source /etc/profile                                                        # 或者： . /etc/profile
    
    # 验证安装结果
    java  -version
    javac -version
```

### 3.2 安装 Scala 并配置环境变量

#### 3.2.1 下载 scala-2.12.17 

  从 [**scala 官网**](https://scala-lang.org/) 下载 [**scala-2.12.17**](https://downloads.lightbend.com/scala/2.12.17/scala-2.12.17.tgz) 压缩包 到本地

#### 3.2.2 解压安装

```bash
    tar -zxvf scala-2.12.17.tgz -C /opt/java/                                  # 解压下载的 scala-2.12.17 压缩包
    cd /opt/java/                                                              # 切换到解压目录
    mv /opt/java/scala-2.12.17 /opt/java/scala-212/                            # 修改目录名称
```

#### 3.2.3 配置环境变量

```bash
    # 使用 vim 编辑器修改系统配置文件
    vim /etc/profile                                                           # 或使用：sudo vim /etc/profile 
    
    # 添加如下内容：
        # ===================================== Scala 2.12.17 ====================================== #
        export SCALA_HOME=/opt/java/scala-212/
        export PATH=${PATH}:${SCALA_HOME}/bin
        
    # 使系统变量生效
    source /etc/profile                                                        # 或者使用： . /etc/profile
```

#### 3.2.4 验证安装

```bash
    scala -version                                                             # 查看安装的版本
    scala                                                                      # 进入交互界面
    println("hello world")                                                     # 打印数据
```

<br/>

<br/>

## 4. 安装 Mysql 数据库

### 4.1 卸载系统自带的 MariaDB

```bash
    sudo rpm -qa | grep maria                                                  # 查看安装的 MariaDB，或者： yum list installed | grep maria 
    sudo rpm -qa | grep mysql                                                  # 查看安装的 myusql， 或者： yum list installed | grep mysql
    sudo rpm -e --nodeps maria-*                                               # 卸载 MariaDB，      或者： yum -y remove maria*
    sudo rpm -e --nodeps mysql-*                                               # 卸载 Mysql，        或者： yum -y remove mysql*
    sudo rm -rf /etc/mysql/ /etc/my.cnf /var/lib/mysql                         # 删除配置文件
    sudo rm -rf /etc/mysql/ /var/lib/mysql                                     # 删除配置文件
```

### 4.2 Mysql 下载与安装

从 [**Mysql 官网**](https://www.mysql.com/) 下载 **[mysql-8.0.31](https://downloads.mysql.com/archives/get/p/23/file/mysql-8.0.31-linux-glibc2.12-x86_64.tar.xz)** 到本地

### 4.3 解压安装

```bash
    sudo apt -y install libaio* libaio-dev*                                    # ubuntu 系列安装必要的系统依赖包
    
    tar -Jxvf mysql-8.0.31-linux-glibc2.12-x86_64.tar.xz -C /opt/db/           # 解压下载的 mysql-8.0.31 压缩包
    cd /opt/db/                                                                # 切换到解压目录
    mv /opt/db/mysql-8.0.31-linux-glibc2.12-x86_64/ /opt/db/mysql/             # 修改目录名称
    mkdir -p /opt/db/mysql/data/                                               # 创建 Mysql 数据存储目录
    mkdir -p /opt/db/mysql/bin-log/                                            # 创建 Mysql bin-log 数据存储目录
    mkdir -p /opt/db/mysql/tmp/                                                # 创建 Mysql 临时文件目录
    mkdir -p /opt/db/mysql/logs/                                               # 创建 Mysql 日志存储目录
    mkdir -p /etc/mysql/                                                       # 创建 Mysql 配置文件目录
    
    touch /etc/mysql/my.cnf                                                    # 创建 Mysql 配置文件，内容如 1.6.4
    cp /etc/mysql/my.cnf /opt/db/mysql/docs/my.cnf                             # 备份配置文件
    sudo chown issac:issac -R /opt/db/mysql/                                   # 将安装目录 mysql 授权给 当前用户
    chmod -R 771 /opt/db/mysql/data/                                           # 修改 数据存储目录 授权
    chmod -R 771 /opt/db/mysql/bin-log/                                        # 修改 bin-log 数据存储目录 授权
    chmod -R 777 /opt/db/mysql/tmp/                                            # 修改 临时文件目录 授权
     
    # 解决 libtinfo.so.5 动态链接库缺失问题
    sudo ln -s /usr/lib/x86_64-linux-gnu/libtinfo.so.6.2 /usr/lib/x86_64-linux-gnu/libtinfo.so.5   # ubuntu
    
    # 解决 libtinfo.so.5 动态链接库缺失问题
    sudo ln -s /usr/lib64/libtinfo.so.6.2 /usr/lib64/libtinfo.so.5             # redhat 
```

### 4.4 添加环境变量

```bash
    # 使用 vim 编辑器修改系统配置文件
    vim /etc/profile                                                           # 或使用：sudo vim /etc/profile 
    
    # 添加如下内容：
        # ===================================== mysql-8.0.31 ====================================== #
        export MYSQL_HOME=/opt/db/mysql
        export PATH=${PATH}:${MYSQL_HOME}/bin
        
    # 使系统变量生效
    source /etc/profile                                                        # 或者使用： . /etc/profile
```

### 4.5 修改配置文件（redhat：/etc/my.cnf；ubuntu：/etc/mysql/my.cnf）

```ini
    [client]
    port                               = 3306
    socket                             = /opt/db/mysql/tmp/mysql.sock
    default-character-set              = utf8mb4
    
    
    [mysql]
    show-warnings
    default-character-set = utf8mb4
    socket                             = /opt/db/mysql/tmp/mysql.sock
    
    
    [mysqldump]
    quick
    quote-names
    max_allowed_packet                 = 16M
    
    
    [mysqld]
    bind-address                       = 0.0.0.0
    port                               = 3306
    
    # Mysql服务的唯一编号 每个 mysql 服务 Id 需唯一
    server-id                          = 1
    
    basedir                            = /opt/db/mysql
    datadir                            = /opt/db/mysql/data
    pid-file                           = /opt/db/mysql/tmp/mysqld.pid
    socket                             = /opt/db/mysql/tmp/mysql.sock
    # 临时目录 比如 load data infile 会用到
    tmpdir                             = /opt/db/mysql/tmp
    log-error                          = /opt/db/mysql/logs/error.log
    
    character-set-server               = utf8mb4
    skip_name_resolve                  = 1
    
    lock_wait_timeout                  = 3600
    open_files_limit                   = 65535
    back_log                           = 1024
    max_connections                    = 512
    max_connect_errors                 = 1000000
    table_open_cache                   = 1024
    table_definition_cache             = 1024
    thread_stack                       = 512K
    sort_buffer_size                   = 32M
    join_buffer_size                   = 64M
    read_buffer_size                   = 128M
    read_rnd_buffer_size               = 16M
    bulk_insert_buffer_size            = 128M
    thread_cache_size                  = 768
    interactive_timeout                = 600
    wait_timeout                       = 600
    tmp_table_size                     = 64M
    max_heap_table_size                = 32M
    # query_cache_size                 = 0
    
    key_buffer_size                    = 32M
    myisam_sort_buffer_size            = 128M
    
    default-storage-engine             = INNODB
    innodb_buffer_pool_size            = 512M
    innodb_buffer_pool_instances       = 4
    # innodb_data_file_path            = ibdata1:12M:autoextend
    innodb_flush_log_at_trx_commit     = 1
    innodb_log_buffer_size             = 32M
    innodb_log_file_size               = 256M
    innodb_log_files_in_group          = 3
    innodb_max_undo_log_size           = 1G
    innodb_io_capacity                 = 400
    innodb_io_capacity_max             = 800
    innodb_open_files                  = 65535
    innodb_flush_method                = O_DIRECT
    innodb_lru_scan_depth              = 4000
    innodb_lock_wait_timeout           = 10
    innodb_rollback_on_timeout         = 1
    innodb_print_all_deadlocks         = 1
    innodb_online_alter_log_max_size   = 4G
    innodb_status_file                 = 1
    innodb_status_output               = 0
    innodb_status_output_locks         = 1
    innodb_sort_buffer_size            = 67108864
    innodb_adaptive_hash_index         = OFF
    
    # log_error_verbosity              = 3
    # slow_query_log                   = 1
    slow_query_log_file                = /opt/db/mysql/logs/slow.log
    # long_query_time                  = 0.1
    # log_queries_not_using_indexes    = 1
    # log_throttle_queries_not_using_indexes = 60
    min_examined_row_limit             = 100
    log_slow_admin_statements          = 1
    log_slow_slave_statements          = 1
    log-bin                            = /opt/db/mysql/bin-log/mysql
    binlog_format                      = ROW
    sync_binlog                        = 1
    binlog_cache_size                  = 16M
    max_binlog_cache_size              = 2G     
    max_binlog_size                    = 1G
    binlog_rows_query_log_events       = 1
    binlog_checksum                    = CRC32
    gtid_mode                          = ON
    enforce_gtid_consistency           = TRUE
    # 大小写不敏感
    lower_case_table_names             = 1
```

### 4.6 修改 ${MYSQL_HOME}/support-files/mysql.server

```bash
    # 1. 将脚本中的变量 basedir 的值统一进行修改为：/opt/db/mysql；
    # 2. 将脚本中的变量 datadir 的值统一进行修改为：/opt/db/mysql/data
    # 3. 将脚本中的变量 bindir  的值统一进行修改为：/opt/db/mysql/bin
    # 4. 将脚本中的变量 sbindir 的值统一进行修改为：/opt/db/mysql/bin
    # 5. 将脚本中的变量 libexecdir 的值统一进行修改为：/opt/db/mysql/bin
    
    # vim 在命令模式下执行如下操作
        :s / \/usr/local / \/opt/db / g
```

### 4.7 修改 ${MYSQL_HOME}/support-files/mysqld_multi.server

```bash

    # 1. 将脚本中的变量 basedir 的值统一进行修改为：/opt/db/mysql
    # 2. 将脚本中的变量 bindir  的值统一进行修改为：/opt/db/mysql/bin
    
    # vim 在命令模式下执行如下操作
        :s / \/usr/local / \/opt/db / g
```

### 4.8 编写 ${MYSQL_HOME}/bin/mysql.sh 启停脚本

```bash
    # 详见 shell 文件夹下：/bigdata-deploy/shell/database/mysql.sh
```

### 4.9 初始化 Mysql 

```bash
    # 切换到 Mysql 安装路径
    cd /opt/db/mysql/ || exit
    
    # 初始化 Mysql 并查看临时密码
    nohup ${MYSQL_HOME}/bin/mysqld --initialize --console > ${MYSQL_HOME}/logs/init.log 2>&1 &
    grep -ni "password" ${MYSQL_HOME}/logs/init.log  
```

### 4.10 启动并测试安装

```bash
    # 启动 Mysql 服务
    ${MYSQL_HOME}/support-files/mysql.server start                             # Mysql 自带脚本启动服务
    ${MYSQL_HOME}/bin/mysql.sh start                                           # 自定义脚本启动 Mysql 
    
    # 查看 Mysql 启动状况
    ${MYSQL_HOME}/support-files/mysql.server status                            # Mysql 自带脚本启动服务
    ${MYSQL_HOME}/bin/mysql.sh status                                          # 自定义脚本查询 Mysql 
    netstat -tunlp | grep 3306                                                 # 查看 Mysql 进程占用端口
    
    # 安装 Mysql 客户端
    sudo pip install mycli                                                     # 基于 Python 的 客户端
    
    # 登录 Mysql
    ${MYSQL_HOME}/bin/mysql -h master -P 3306 -u root -p Y2>yhAy>E%uV -D mysql  # Mysql 自带客户端连接 Mysql 服务
    mycli -h master -P 3306 -u root -p Y2>yhAy>E%uV -D mysql                    # 使用临时密码进行登录
```

### 4.11 后续处理

```mysql
    # 修改密码策略
    set global validate_password.policy=LOW;                                   # 修改密码复杂度
    set global validate_password.length=6;                                     # 修改密码长度
    
    # 修改密码并允许远程登录
    alter user 'root'@'localhost' identified by '111111';                      # 修改密码为六个 1
    update mysql.user set host = '%' where user = 'root';                      # 使 root 能在任何 host 访问
    flush privileges;                                                          # 刷新权限，使得修改生效
    
    # 退出登录，重新登录
    quit;                                                                      # 退出登录
    mycli -h master -P 3306 -u root -p 111111 -D mysql                         # 使用修改后的密码进行登录
    
    # 创建 数据库
    create database if not exists other;                                       # 创建 other 数据库
    create database if not exists mock;                                        # 创建 test  数据库
    create database if not exists hive;                                        # 创建 hive  数据库
    create database if not exists kylin;                                       # 创建 kylin 数据库
    
    # 创建 用户
    create user if not exists 'issac'@'%' identified by '111111';              # 创建 issac 用户，密码六个 1
    
    # 将创建的 数据库，权限授权给 创建的用户
    grant all privileges on other.* to 'issac'@'%';                            # 将数据库 other 的所有授权给用户 issac
    grant all privileges on mock.*  to 'issac'@'%';                            # 将数据库 test  的所有授权给用户 issac
    grant all privileges on hive.*  to 'issac'@'%';                            # 将数据库 hive  的所有授权给用户 issac
    grant all privileges on kylin.* to 'issac'@'%';                            # 将数据库 kylin 的所有授权给用户 issac
    flush privileges;                                                          # 刷新权限
    
    # 退出登录，使用创建的 issac 用户重新登录，并测试
    quit;                                                                      # 退出登录，或者：\q;
    mycli -h master -P 3306 -u issac -p 111111 -D test                         # 使用修改后的密码进行登录
    show tables;                                                               # 查看 test 下的所有表
    create table if not exists test                                            # 创建 test 表
    (
        id   int          primary key,
        name varchar(64)  not null    default '',
        mark varchar(255) not null    default '未知' 
    ) engine = InnoDB;
    show create table test;
    insert into test (id, name, mark) values (101, 'issac', 'qazwsx');
    select * from test;
    quit;
```

<br/>

<br/>

## 5. 安装 Maven

### 5.1 Maven 下载

  从 [**阿里云镜像网站**](https://mirrors.aliyun.com/apache/) 下载 **[maven-3.6.3](https://mirrors.aliyun.com/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz)** 到本地

### 5.2 解压安装

```bash
    tar -zxvf apache-maven-3.6.3-bin.tar.gz -C /opt/apache/                    # 解压下载的 maven-3.6.3 压缩包
    cd /opt/apache/                                                            # 切换到解压目录
    mv apache-maven-3.6.3/ maven/                                              # 修改目录名称
```

### 5.3 修改 ${MAVEN_HOME}/conf/settings.xml 配置文件

```xml 
    <localRepository>/opt/apache/maven/data</localRepository>
    
    <pluginGroups></pluginGroups>
    <proxies></proxies>
    <servers></servers>
    
    <mirrors>
        <!--阿里云-->
        <mirror>
            <id>alimaven</id>
            <mirrorOf>*</mirrorOf>
            <name>阿里云公共仓库</name>
            <url>https://maven.aliyun.com/repository/public</url>
        </mirror>
    </mirrors>
    
    <repositories>
        <repository>
            <id>spring</id>
            <url>https://maven.aliyun.com/repository/spring</url>
            <releases><enabled>true</enabled></releases>
            <snapshots><enabled>true</enabled></snapshots>
        </repository>
    </repositories>
    
    <profiles>
        <profile>
            <id>jdk8</id>
            <activation>
                <activeByDefault>true</activeByDefault>
                <jdk>1.8</jdk>
            </activation>
            <properties>
                <maven.compiler.source>1.8</maven.compiler.source>
                <maven.compiler.target>1.8</maven.compiler.target>
                <maven.compiler.compilerVersion>1.8</maven.compiler.compilerVersion>
            </properties>
        </profile>
    </profiles>
```

### 5.4 配置环境变量

```bash
    # 使用 vim 编辑器修改系统配置文件
    vim /etc/profile                                                           # 或使用： sudo vim /etc/profile 
    
    # 添加如下内容：
        # ===================================== Maven 3.6.3 ====================================== #
        export MAVEN_HOME=/opt/apache/maven
        export PATH=${PATH}:${MAVEN_HOME}/bin
        
    # 使系统变量生效
    source /etc/profile                                                        # 或者使用： . /etc/profile
```

### 5.5 测试安装

```bash
    mvn -v
```

<br/>

<br/>

## 6. Hadoop 安装配置

### 6.1 下载 Hadoop-3.2.4

  从 [**阿里云镜像网站**](https://mirrors.aliyun.com/apache/) 下载 **[hadoop-3.2.4](https://mirrors.aliyun.com/apache/hadoop/common/hadoop-3.2.4/hadoop-3.2.4.tar.gz)** 到本地

### 6.2 解压安装

```bash
    tar -zxvf hadoop-3.2.4.tar.gz -C /opt/apache/                              # 解压下载的 hadoop-3.2.4 压缩包
    cd /opt/apache/                                                            # 切换到解压目录
    mv hadoop-3.2.4/ hadoop/                                                   # 修改目录名称
    
    # 切换 root 账户，配置系统的环境变量
    su - root                                                                  # 切换到 root 账户，或者使用 sudo 
    
    # 使用 vim 编辑器修改系统配置文件
    vim /etc/profile                                                           # 或使用： sudo vim /etc/profile 
    
    # 添加如下内容：
        # ===================================== Hadoop 3.2.4 ====================================== #
        export HADOOP_HOME=/opt/apache/hadoop
        export PATH=${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin
        export HADOOP_CLASSPATH=${HADOOP_CLASSPATH}:${HADOOP_HOME}/share/hadoop/common/lib/*:${HADOOP_HOME}/share/hadoop/common/*:${HADOOP_HOME}/share/hadoop/hdfs:${HADOOP_HOME}/share/hadoop/hdfs/lib/*:${HADOOP_HOME}/share/hadoop/hdfs/*:${HADOOP_HOME}/share/hadoop/mapreduce/lib/*:${HADOOP_HOME}/share/hadoop/mapreduce/*:${HADOOP_HOME}/share/hadoop/yarn:${HADOOP_HOME}/share/hadoop/yarn/lib/*:${HADOOP_HOME}/share/hadoop/yarn/*
        
    # 使系统变量生效
    source /etc/profile                                                        # 或者使用： . /etc/profile
    
    # 验证安装
    hadoop version
```

### 6.3 修改配置文件（${HADOOP_HOME}/etc/hadoop/）

#### 6.3.1 编辑 ${HADOOP_HOME}/etc/hadoop/hadoop-env.sh 添加以下内容

```bash
    export JAVA_HOME=/opt/java/jdk-08
    export HADOOP_HOME=/opt/apache/hadoop
    # export HADOOP_OS_TYPE=${HADOOP_OS_TYPE:-$(uname -s)}
```

#### 6.3.2 编辑 ${HADOOP_HOME}/etc/hadoop/yarn-env.sh 添加以下内容

```bash
    export JAVA_HOME=/opt/java/jdk-08
```

#### 6.3.3 编辑 ${HADOOP_HOME}/etc/hadoop/core-site.xml 添加以下内容

```xml
    <configuration>
        <!-- Hadoop 的临时文件夹位置 -->
        <property>
            <name>hadoop.tmp.dir</name>
            <value>/opt/apache/hadoop/data/tmp</value>
        </property>
        <!-- 访问 HDFS 时的 host 和 port -->
        <property>
            <name>fs.default.name</name>
            <value>hdfs://master:9000</value>
        </property>
        
        <!-- 缓冲区大小，根据服务器性能动态调整 -->
        <property>
            <name>io.file.buffer.size</name>
            <value>4096</value>
        </property>
        <!--  开启 HDFS 的垃圾桶机制，删除掉的数据可以从垃圾桶中回收，单位分钟 -->
        <property>
            <name>fs.trash.interval</name>
            <value>10080</value>
        </property>
        <!-- 开启 HDFS 支持压缩 -->
        <property>
            <name>io.compression.codecs</name>
            <value>org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec</value>
        </property>
        <!-- 开启 Map 阶段文件压缩 -->
        <property>
            <name>mapreduce.map.output.compress</name>
            <value>true</value>
        </property>
        <!-- 设置 Map 阶段文件压缩编码 -->
        <property>
            <name>mapreduce.map.output.compress.codec</name>
            <value>org.apache.hadoop.io.compress.GzipCodec</value>
        </property>
        <!-- 开启 MapReduce 输出文件压缩 -->
        <property>
            <name>mapreduce.output.fileoutputformat.compress</name>
            <value>true</value>
        </property>
        <!-- 设置 MapReduce 输出文件压缩编码 -->
        <property>
            <name>mapreduce.output.fileoutputformat.compress.codec</name>
            <value>org.apache.hadoop.io.compress.GzipCodec</value>
        </property>
        
        <!-- 设置 root 账户在 Web 页面登录的代理 -->
        <property>
            <name>hadoop.proxyuser.root.hosts</name>
            <value>*</value>
        </property>
        <property>
            <name>hadoop.proxyuser.root.groups</name>
            <value>*</value>
        </property>
        
        <!-- 设置 issac 账户在 Web 页面登录的代理 -->
        <property>
            <name>hadoop.proxyuser.issac.hosts</name>
            <value>*</value>
        </property>
        <property>
            <name>hadoop.proxyuser.issac.groups</name>
            <value>*</value>
        </property>
        
        <!-- 高可用时，NameNode 访问 ZK 的地址 -->
        <property>
            <name>ha.zookeeper.quorum</name>
            <value>slaver1:2181,slaver2:2181,slaver3:2181</value>
        </property>
    </configuration>
```

#### 6.3.4 编辑 ${HADOOP_HOME}/etc/hadoop/hdfs-site.xml 添加以下内容

```xml
    <configuration>
        <!-- 集群动态上下线 -->
        <!--
        <property>
            <name>dfs.hosts</name>
            <value>/opt/apache/hadoop/etc/hadoop/accept-host</value>
        </property>
        <property>
            <name>dfs.hosts.exclude</name>
            <value>/opt/apache/hadoop/etc/hadoop/deny-host</value>
        </property>
        -->
        <!-- 配置 NameNode 的存放位置 -->
        <property>
            <name>dfs.namenode.name.dir</name>
            <value>/opt/apache/hadoop/data/namenode</value>
        </property>
        <!-- 定义 DataNode 数据存储的节点位置，一般先确定磁盘的挂载目录，然后多个目录用，进行分割 -->
        <property>
            <name>dfs.datanode.data.dir</name>
            <value>/opt/apache/hadoop/data/datanode</value>
        </property>
        <!-- Edits 的存储位置 -->
        <property>
            <name>dfs.namenode.edits.dir</name>
            <value>/opt/apache/hadoop/data/edits</value>
        </property>
        <!-- 元数据信息检查点的存储位置 -->
        <property>
            <name>dfs.namenode.checkpoint.dir</name>
            <value>/opt/apache/hadoop/data/metapoint</value>
        </property>
        <!-- Edits 的检查点的存储位置 -->
        <property>
            <name>dfs.namenode.checkpoint.edits.dir</name>
            <value>/opt/apache/hadoop/data/editpoint</value>
        </property>
        <!-- 副本数量 -->
        <property>
            <name>dfs.replication</name>
            <value>3</value>
        </property>
        
        <!-- NameNode 有一个工作线程池，默认值是 10 -->
        <property>
            <name>dfs.namenode.handler.count</name>
            <value>10</value>
        </property>
        <!-- 2NN 的访问路径和端口号 -->
        <property>
            <name>dfs.namenode.secondary.http-address</name>
            <value>0.0.0.0:9860</value>
        </property>
        <!-- NameNode 的外部访问路径和端口号 -->
        <property>
            <name>dfs.namenode.http-address</name>
            <value>0.0.0.0:9870</value>
        </property>
        <!-- 关闭 HDFS 的验证权限 -->
        <property>
            <name>dfs.permissions</name>
            <value>false</value>
        </property>
        <!-- HDFS 存储块的大小，4M -->
        <property>
            <name>dfs.blocksize</name>
            <value>4194304</value>
        </property>
        <!-- HDFS NameNode 最小块限制，4M -->
        <property>
            <name>dfs.namenode.fs-limits.min-block-size</name>
            <value>4194304</value>
        </property>
        <!-- 开启 HDFS WEB UI -->
        <property>
            <name>dfs.webhdfs.enabled</name>
            <value>true</value>
        </property>
        <!-- Zookeeper -->
        <property>
            <name>ha.zookeeper.quorum</name>
            <value>slaver1:2181,slaver2:2181,slaver3:2181</value>
        </property>
    </configuration>
```

#### 6.3.5 编辑 ${HADOOP_HOME}/etc/hadoop/mapred-site.xml 添加以下内容

```xml
    <configuration>
        <!-- 配置 MapReduce 在 Yarn 集群上运行(默认本地运行) -->
        <property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
        </property>
        
        <!-- 开启 MapReduce 的小任务模式：开启 uber 模式，使用 JVM 重用，默认关闭 -->
        <property>
            <name>mapreduce.job.ubertask.enable</name>
            <value>true</value>
        </property>
        
        <!-- Uber 模式中最大的 MapTask 数量，可向下修改 --> 
        <property>
            <name>mapreduce.job.ubertask.maxmaps</name>
            <value>8</value>
        </property>
        
        <!-- Uber 模式中最大的 Reduce 数量，可向下修改 -->
        <property>
            <name>mapreduce.job.ubertask.maxreduces</name>
            <value>8</value>
        </property>
        
        <!-- Uber 模式中最大的输入数据量，默认使用 dfs.blocksize 的值，可向下修改 -->
        <property>
            <name>mapreduce.job.ubertask.maxbytes</name>
            <value>4194304</value>
        </property>
        
        <!-- 环形缓冲区大小，默认 100M -->
        <property>
            <name>mapreduce.task.io.sort.mb</name>
            <value>100</value>
        </property>
        
        <!-- 环形缓冲区溢写阈值，默认 0.8 -->
        <property>
            <name>mapreduce.map.sort.spill.percent</name>
            <value>0.80</value>
        </property>
        
        <!-- Merge 合并次数，默认 10 个 -->
        <property>
            <name>mapreduce.task.io.sort.factor</name>
            <value>10</value>
        </property>
        
        <!-- MapTask 内存，默认 1g； MapTask 堆内存大小默认和该值大小一致 mapreduce.map.java.opts -->
        <property>
            <name>mapreduce.map.memory.mb</name>
            <value>-1</value>
        </property>
        
        <!-- MapTask 的 CPU 核数，默认 1 个 -->
        <property>
            <name>mapreduce.map.cpu.vcores</name>
            <value>1</value>
        </property>
        
        <!-- MapTask 异常重试次数，默认 4 次 -->
        <property>
            <name>mapreduce.map.maxattempts</name>
            <value>4</value>
        </property>
        
        <!-- 每个 Reduce 去 Map 中拉取数据的并行数，默认值是 5 -->
        <property>
            <name>mapreduce.reduce.shuffle.parallelcopies</name>
            <value>8</value>
        </property>
        
        <!-- Buffer 大小占 Reduce 可用内存的比例，默认值 0.7 -->
        <property>
            <name>mapreduce.reduce.shuffle.input.buffer.percent</name>
            <value>0.70</value>
        </property>
        
        <!-- Buffer 中的数据达到多少比例开始写入磁盘，默认值 0.66 -->
        <property>
            <name>mapreduce.reduce.shuffle.merge.percent</name>
            <value>0.66</value>
        </property>
        
        <!-- ReduceTask 内存，默认 1g；ReduceTask 堆内存大小默认和该值大小一致 mapreduce.reduce.java.opts -->
        <property>
            <name>mapreduce.reduce.memory.mb</name>
            <value>-1</value>
        </property>
        
        <!-- ReduceTask 的 CPU 核数，默认 1 个 -->
        <property>
            <name>mapreduce.reduce.cpu.vcores</name>
            <value>1</value>
        </property>
        
        <!-- ReduceTask 失败重试次数，默认 4 次 -->
        <property>
            <name>mapreduce.reduce.maxattempts</name>
            <value>4</value>
        </property>
        
        <!-- 当 MapTask 完成的比例达到该值后才会为 ReduceTask 申请资源，默认是 0.05 -->
        <property>
            <name>mapreduce.job.reduce.slowstart.completedmaps</name>
            <value>0.05</value>
        </property>
        
        <!-- 如果程序在规定的默认 10 分钟内没有读到数据，将强制超时退出 -->
        <property>
            <name>mapreduce.task.timeout</name>
            <value>600000</value>
        </property>
        <!-- 配置 JobHistory 的访问路径和端口号，JobHistory 是执行完成的任务日志 -->
        <property>
            <name>mapreduce.jobhistory.address</name>
            <value>0.0.0.0:10020</value>
        </property>
        <!-- 配置 JobHistory 的浏览器访问路径和端口号 -->
        <property>
            <name>mapreduce.jobhistory.webapp.address</name>
            <value>0.0.0.0:19888</value>
        </property>
    </configuration>
```

#### 6.3.6 编辑 ${HADOOP_HOME}/etc/hadoop/yarn-site.xml 添加以下内容

```xml
    <configuration>
        <!-- 配置 ResourceManager 运行的机器地址 -->
        <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>master</value>
        </property>
        <!-- Yarn WEB UI 地址 -->
        <property>
            <name>yarn.resourcemanager.webapp.address</name>
            <value>0.0.0.0:8088</value>
        </property>
        <!-- 调度器地址 -->
        <property>
            <name>yarn.resourcemanager.scheduler.address</name>
            <value>master:8098</value>
        </property>
        <!-- 配置 NodeManager 上运行的附属服务为 shuffle：需要配置成 mapreduce_shfffle，才可运行 MapReduce 程序默认值 -->
        <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
        </property>
        <!-- 每个节点可用最小内存, 单位 MB, 默认 1024 MB -->
        <property>
            <name>yarn.scheduler.minimum-allocation-mb</name>
            <value>512</value>
        </property>
        <!-- 每个节点可用内存, 单位 MB, 默认 8192 MB -->
        <property>
            <name>yarn.scheduler.maximum-allocation-mb</name>
            <value>8192</value>
        </property>
        <!-- 容器允许管理的物理内存大小，单位 MB， 默认 4096 MB -->
        <property>
            <name>yarn.nodemanager.resource.memory-mb</name>
            <value>12288</value>
        </property>
        <property>
            <name>yarn.nodemanager.vmem-pmem-ratio</name>
            <value>2.1</value>
        </property>
        <!-- 关闭 yarn 对物理内存的限制检查 -->
        <property>
            <name>yarn.nodemanager.pmem-check-enabled</name>
            <value>false</value>
        </property>
        <!-- 关闭 yarn 对虚拟内存的限制检查 -->
        <property>
            <name>yarn.nodemanager.vmem-check-enabled</name>
            <value>false</value>
        </property>
        <!-- 可使用的 CPU Core -->
        <property>
          <name>yarn.nodemanager.resource.cpu-vcores</name>
          <value>4</value>
        </property>
        
        <!-- 开启日志聚集功能 -->
        <property>      
            <name>yarn.log-aggregation-enable</name>
            <value>true</value>
        </property>
        <!-- 设置日志聚集服务器地址 -->
        <property>
            <name>yarn.log.server.url</name>
            <value>http://0.0.0.0:19888/jobhistory/logs</value>
        </property>
        <!-- 配置聚合日志保留时间为 7 天 -->
        <property>
            <name>yarn.log-aggregation.retain-seconds</name>
            <value>604800</value>
        </property>
        
        <!-- 每个 MapReduce 初始化堆大小 -->
        <property>
            <name>mapreduce.child.java.opts</name>
            <value>-Xmx512m</value>
        </property>
        <!-- Yarn 的 ClassPath -->
        <property>
            <name>yarn.application.classpath</name>
            <value>/opt/apache/hadoop/etc/hadoop:/opt/apache/hadoop/share/hadoop/common/lib/*:/opt/apache/hadoop/share/hadoop/common/*:/opt/apache/hadoop/share/hadoop/hdfs:/opt/apache/hadoop/share/hadoop/hdfs/lib/*:/opt/apache/hadoop/share/hadoop/hdfs/*:/opt/apache/hadoop/share/hadoop/mapreduce/lib/*:/opt/apache/hadoop/share/hadoop/mapreduce/lib-examples/*:/opt/apache/hadoop/share/hadoop/mapreduce/*:/opt/apache/hadoop/share/hadoop/yarn:/opt/apache/hadoop/share/hadoop/yarn/lib/*:/opt/apache/hadoop/share/hadoop/yarn/*:/opt/apache/hadoop/share/hadoop/yarn/timelineservice/*</value>
        </property>
        
        <!-- 配置使用公平调度器 -->
        <!-- 
        <property>
            <name>yarn.resourcemanager.scheduler.class</name>
            <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>       
        </property>
         -->
        <!-- 指明公平调度器队列分配配置文件 -->
        <!-- 
        <property>
            <name>yarn.scheduler.fair.allocation.file</name>
            <value>/opt/apache/hadoop/etc/hadoop/fair-scheduler.xml</value>
        </property>
         -->
        <!-- 禁止队列间资源抢占 -->
        <property>
            <name>yarn.scheduler.fair.preemption</name>
            <value>false</value>
        </property>
        <!-- ResourceManager 处理调度器请求的线程数量，默认 50；如果提交的任务数大于 50，可以增加该值 -->
        <property>
            <name>yarn.resourcemanager.scheduler.client.thread-count</name>
            <value>50</value>
        </property>
    </configuration>
```

#### 6.3.7 编辑 ${HADOOP_HOME}/etc/hadoop/workers 添加以下内容

```yaml
    slaver1
    slaver2
    slaver3
```

### 6.4 创建数据和日志存储路径

```bash
    cd /opt/apache/hadoop/                                                     # 切换到安装路径
    mkdir -p ${HADOOP_HOME}/data                                               # 创建 数据存储 目录
    mkdir -p ${HADOOP_HOME}/logs                                               # 创建 日志存储 目录
    
    cd /opt/apache/hadoop/data                                                 # 切换到数据存储路径
    mkdir -p ${HADOOP_HOME}/data/tmp                                           # 创建 临时存储 路径
    mkdir -p ${HADOOP_HOME}/data/namenode                                      # 创建 NameNode 数据存储路径
    mkdir -p ${HADOOP_HOME}/data/datanode                                      # 创建 DataNode 数据存储路径
    mkdir -p ${HADOOP_HOME}/data/edit                                          # 创建 编辑日志 存储路径
    mkdir -p ${HADOOP_HOME}/data/metapoint                                     # 创建 元数据信息检查点 存储路径
    mkdir -p ${HADOOP_HOME}/data/editpoint                                     # 创建 编辑日志检查点 存储路径
```

### 6.5 分发到其它节点并格式化

```bash
    xync.sh hadoop                                                             # 同步 hadoop 到其它节点，xync.sh 详见 /offline-data-warehouse/deploy/shell/xync.sh
    
    ${HADOOP_HOME}/bin/hadoop namenode -format > ${HADOOP_HOME}/logs/format.log 2>&1 &   # 格式化 namenode
    grep -ni "successfully formatted" ${HADOOP_HOME}/logs/format.log           # 查看格式化结果
    
    ${HADOOP_HOME}/sbin/start-all.sh                                           # 启动 hdfs、yarn 集群
    ${HADOOP_HOME}/sbin/mr-jobhistory-daemon.sh start historyserver            # 启动 HistoryServer 集群
    
    xcall "jps -l"                                                             # 查看 hadoop 启动的 jvm 进程，xcall.sh 详见 /offline-data-warehouse/deploy/shell/xcall.sh
    http://master:9870                                                         # 浏览器访问 NameNode
    http://master:9860                                                         # 浏览器访问 2NN
    http://master:8088/cluster                                                 # 浏览器访问 Yarn
    http://master:19888/jobhistory                                             # 浏览器访问 历史服务器
    
    # 计算 pi 
    ${HADOOP_HOME}/bin/hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.4.jar pi 10 10
    
    # 计算
    ${HADOOP_HOME}/bin/hadoop fs -mkdir -p /hadoop/test/wc/input               # 创建 hdfs 数据输入目录
    ${HADOOP_HOME}/bin/hadoop fs -ls /hadoop/test/wc/input                     # 查看创建的目录
    ${HADOOP_HOME}/bin/hadoop fs -put ${HADOOP_HOME}/*.txt /hadoop/test/wc/input    # 上传文件到 hdfs
    ${HADOOP_HOME}/bin/hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.4.jar wordcount /hadoop/test/wc/input /hadoop/test/wc/output
    ${HADOOP_HOME}/bin/hadoop fs -cat /hadoop/test/wc/output/part-r-00000  # 查看统计结果
```

<br/>

## 7. Spark 安装配置

### 7.1 下载 Spark-3.2.3 源码

  从 [**阿里云镜像网站**](https://mirrors.aliyun.com/apache/) 下载 **[spark-3.2.3 源码](https://mirrors.aliyun.com/apache/spark/spark-3.2.3/spark-3.2.3.tgz)** 和不含有 hadoop 的 [**spark-3.2.3**](https://mirrors.aliyun.com/apache/spark/spark-3.2.3/spark-3.2.3-bin-without-hadoop.tgz) 到本地

### 7.2 编译 Spark（spark-3.2.3 和 hadoop-3.2.4 在兼容性上存在问题，需要修改源码重新编译）

```bash
    git clone https://github.com/apache/spark.git                              # 使用 git 下载源码
    git branch                                                                 # 查看本地分支
    git branch -r                                                              # 查看远程分支，-r 表示 remote
    git branch -a                                                              # 查看所有分支
    git checkout v3.2.3                                                        # 切换到 3.2.3 分支
    
    # 编译 spark-3.2.3
    ./dev/make-distribution.sh --name build --tgz -Phive-3.1 -Phive-thriftserver -Phadoop-3.2 -Phadoop-provided -Pyarn -Pscala-2.12 -Dhadoop.version=3.2.4 -DskipTests
        
    git apply --check ./spark.patch                                            # 检查 patch 是否可用，补丁内容：https://github.com/lihuashiyu/bigdata-deploy/blob/main/patch/issac-hive.patch 
    git apply ./spark.patch                                                    # 应用补丁，不包含 commit 内容
    git am ./spark.patch                                                       # 应用补丁，包含 commit 内容
    
    # 再次编译
    ./dev/make-distribution.sh --name build --tgz -Phive-3.1 -Phive-thriftserver -Phadoop-3.2 -Phadoop-provided -Pyarn -Pscala-2.12 -Dhadoop.version=3.2.4 -DskipTests
```

### 7.3 解压安装 Spark

```bash
    cd ~/coding/java/src/spark/ || exit                                        # 切换到解压目录
    tar -zxf spark-3.2.3-bin-build.tgz -C /opt/apache/                         # 解压编译后的压缩包
    mv /opt/apache/spark-3.2.3-bin-build/ /opt/apache/spark                    # 修改目录名称
    mkdir -p /opt/apache/spark/logs/                                           # 创建日志目录
    
    # 切换 root 账户，配置系统的环境变量
    su - root                                                                  # 切换到 root 账户，或者使用 sudo 
    
    # 使用 vim 编辑器修改系统配置文件
    vim /etc/profile                                                           # 或使用： sudo vim /etc/profile 
    
    # 添加如下内容：
        # ===================================== Spark 3.2.3 ====================================== #
        export SPARK_HOME=/opt/apache/spark
        export PATH=$PATH:${SPARK_HOME}/bin
        
    # 使系统变量生效
    source /etc/profile                                                        # 或者使用： . /etc/profile 
```

### 7.4 修改配置文件

#### 9.3.1 添加如下配置文件

```bash
    cd /opt/apache/spark/                                                      # 切换到 spark 安装目录
    touch ${SPARK_HOME}/conf/spark-env.sh
    touch ${SPARK_HOME}/conf/spark-defaults.conf
    touch ${SPARK_HOME}/spark/conf/workers
    cp ${SPARK_HOME}/conf/log4j.properties.template ${SPARK_HOME}/conf/log4j.properties
```

#### 9.3.2 修改 ${SPARK_HOME}/conf/spark-env.sh 

```bash
    # 添加如下内容
    export JAVA_HOME=/opt/java/jdk-08
    export SCALA_HOME=/opt/java/scala-212
    export HADOOP_HOME=/opt/apache/hadoop
    export SPARK_HOME=/opt/apache/spark
    
    export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
    export YARN_CONF_DIR=${HADOOP_HOME}/etc/hadoop
    # export SPARK_MASTER_HOST=master
    export SPARK_CONF_DIR=${SPARK_HOME}/conf
    
    export SPARK_HISTORY_OPTS="
        -Dspark.history.ui.port=18080 
        -Dspark.history.fs.logDirectory=hdfs://master:9000/spark/logs 
        -Dspark.history.retainedApplications=30"
    
    export SPARK_DIST_CLASSPATH=$(${HADOOP_HOME}/bin/hadoop classpath)
```

#### 9.3.3 修改 ${SPARK_HOME}/conf/spark-defaults.conf 

```bash
    # 添加如下内容
    spark.master                      yarn
    spark.eventLog.enabled            true
    spark.eventLog.dir                hdfs://master:9000/spark/logs
    spark.yarn.jars                   hdfs://master:9000/spark/jars/*
    spark.history.fs.logDirectory     hdfs://master:9000/spark/history
    
    spark.serializer                  org.apache.spark.serializer.KryoSerializer
    spark.driver.memory               6g
    spark.executor.memory             8g
    
    spark.yarn.historyServer.address  http://0.0.0.0:18080
    spark.history.ui.port             18080
```

#### 9.3.4 修改 ${SPARK_HOME}/conf/works

```bash
    slaver1
    slaver2
    slaver3
```

### 9.4 上传 jar 到 hdfs，分发启动

```bash
    # 在 hdfs 上创建 spark 需要的目录
    ${HADOOP_HOME}/bin/hadoop fs -mkdir -p /spark/                             # hdfs 上的 spark 工作目录
    ${HADOOP_HOME}/bin/hadoop fs -mkdir -p /spark/jars                         # 不带 hadoop 的 spark 依赖
    ${HADOOP_HOME}/bin/hadoop fs -mkdir -p /spark/logs                         # spark 日志存放目录
    ${HADOOP_HOME}/bin/hadoop fs -mkdir -p /spark/history                      # spark 历史服务器目录
    
    # 上传不带 hadoop 的 spark 依赖
    tar -zxvf spark-3.2.3-bin-without-hadoop.tgz                               # 解压下载的不带 hadoop 的 spark 安装包
    ${HADOOP_HOME}/bin/hadoop fs -put spark-3.2.3-bin-without-hadoop/jars/* /spark/jars/ # 上传文件到 hdfs
    
    xync.sh spark                                                              # 同步 spark 到其它节点
    ${SPARK_HOME}/sbin/start-all.sh                                            # 启动 master 和 worker 节点
    ${SPARK_HOME}/sbin/start-history-server.sh                                 # 启动历史服务器
    
    xcall "jps -l"                                                             # 查看 spark 启动的 jvm 进程
    http://master:8080                                                         # 浏览器访问 SparkMaster
    http://master:4040                                                         # 浏览器访问 SparkUI
    http://master:18080                                                        # 浏览器访问 历史服务器
    
    # 计算 pi 
    ${SPARK_HOME}/bin/spark-submit --class org.apache.spark.examples.SparkPi --master local[*] ${SPARK_HOME}/examples/jars/spark-examples_2.12-3.2.3.jar 100
    ${SPARK_HOME}/bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://master:7077 --deploy-mode cluster ${SPARK_HOME}/examples/jars/spark-examples_2.12-3.2.3.jar 100
    ${SPARK_HOME}/bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode cluster --driver-memory 1G --executor-memory 1G --num-executors 3 --executor-cores 2 ${SPARK_HOME}/examples/jars/spark-examples_2.12-3.2.3.jar
    ${SPARK_HOME}/bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client  --driver-memory 1G --executor-memory 1G --num-executors 3 --executor-cores 2 ${SPARK_HOME}/examples/jars/spark-examples_2.12-3.2.3.jar
    
    # 计算 wc
    ${HADOOP_HOME}/bin/hadoop fs -mkdir -p /spark/test/wc/input                # 创建 hdfs 数据输入目录
    ${HADOOP_HOME}/bin/hadoop fs -ls /hadoop/test/wc/input                     # 查看创建的目录
    ${HADOOP_HOME}/bin/hadoop fs -put ${SPARK_HOME}/RELEASE /spark/test/wc/input    # 上传文件到 hdfs
    ${SPARK_HOME}/bin/spark-submit --class com.example.spark.ScalaWordCount --master yarn --deploy-mode client --driver-memory 1G --executor-memory 1G --total-executor-cores 2 ~/coding/java/jar/wc-1.0.jar hdfs:///spark/test/input
```

<br/>

<br/>

## 8. Zookeeper 安装

### 8.1 zookeeper-3.6.4 下载

从 [**阿里云镜像网站**](https://mirrors.aliyun.com/apache/) 下载 **[zookeeper-3.6.4](https://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.6.4/apache-zookeeper-3.6.4-bin.tar.gz)** 安装包到本地

### 8.2 解压安装 zookeeper

```bash
    tar -zxvf apache-zookeeper-3.6.4-bin.tar.gz -C /opt/apache/                # 解压编译后的压缩包
    mv /opt/apache/apache-zookeeper-3.6.4-bin /opt/apache/zookeeper            # 修改目录名称
    mkdir -p /opt/apache/zookeeper/data/                                       # 创建数据存储目录
    mkdir -p /opt/apache/zookeeper/logs/                                       # 创建日志目录
    
    # 使用 vim 编辑器修改系统配置文件
    vim /etc/profile                                                           # 或使用： sudo vim /etc/profile 
    
    # 添加如下内容：
        # ===================================== Zookeeper 3.6.4 ====================================== #
        export ZOOKEEPER_HOME=/opt/apache/zookeeper
        export PATH=${PATH}:${ZOOKEEPER_HOME}/bin
        
    # 使系统变量生效
    source /etc/profile                                                        # 或者使用： . /etc/profile 
```

### 8.3 修改配置文件

#### 8.3.1 创建配置文件

```bash
    cd ${ZOOKEEPER_HOME}/conf/ || exit                                         # 切换到 zookeeper 配置文件目录
    touch /opt/apache/zookeeper/conf/zoo.cfg                                   # zookeeper 主要配置文件
    cp ${ZOOKEEPER_HOME}/conf/log4j.properties.template ${ZOOKEEPER_HOME}/conf/log4j.properties    # 日志配置文件
    mkdir -p ${ZOOKEEPER_HOME}/data                                            # 创建 ZK 数据存储目录
    mkdir -p ${ZOOKEEPER_HOME}/logs                                            # 创建 ZK 日志存储目录
```

#### 8.3.2 修改 ${ZOOKEEPER_HOME}/conf/zoo.cfg 

```bash
    # 用来调节心跳和超时, 默认的会话超时时间是两倍的 tickTime
    tickTime=2000
    
    # 用于配置允许 followers 连接并同步到 leader 的最大时间
    initLimit=10
    
    # 配置leader 和 followers 间进行心跳检测的最大延迟时间
    syncLimit=5
    
    # 存储内存数据库快照目录, 并且除非指定其它目录, 否则数据库更新的事务日志也将会存储在该目录下
    dataDir=/opt/apache/zookeeper/data
    
    # 配置 dataLogDir 参数来指定 ZooKeeper 事务日志的存储目录
    dataLogDir=/opt/apache/zookeeper/logs
    
    # 服务器监听客户端连接的端口, 也即客户端尝试连接的端口, 默认值是 2181 
    clientPort=2181
    
    # 不然会出现端口被占用的情况，因为默认是和 Apache.Tomcat 使用的 8080 端口
    admin.serverPort=8180
    
    # 限制单个客户端与单台服务器之前的并发连接数量, 可以通过 IP 地址来区分不同的客户端，它用来防止某种类型的 DoS 攻击, 将其设置为 0 将完全移除并发连接数的限制
    # maxClientCnxns=60
    
    # ZooKeeper 自动清理时需要保留的数据文件快照的数量和对应的事务日志文件, 默认值是 3
    # autopurge.snapRetainCount=3
    
    # 和 autopurge.snapRetainCount 配套使用, 用于配置 ZooKeeper 自动清理文件的频率，默认值是 1, 即默认开启自动清理功能, 设置为 0 则表示禁用自动清理功能。
    # autopurge.purgeInterval=1
    
    
    ## Metrics Providers
    # https://prometheus.io Metrics Exporter
    #metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider
    #metricsProvider.httpPort=7000
    #metricsProvider.exportJvmInfo=true
    
    # 服务器唯一标识，各个节点中，自己的节点要修改为：server.*=0.0.0.0:2888:3888
    server.1=slaver1:2888:3888
    server.2=slaver2:2888:3888
    server.3=slaver3:2888:3888
```

#### 8.3.3 创建 ${ZOOKEEPER_HOME}/data/myid

```bash
    # 创建每个节点独有的版本号
    echo "1" >> ${ZOOKEEPER_HOME}/data/myid                                    # slaver1
    echo "2" >> ${ZOOKEEPER_HOME}/data/myid                                    # slaver2
    echo "3" >> ${ZOOKEEPER_HOME}/data/myid                                    # slaver3
```


### 8.4 启动 Zookeeper 并验证

```bash
    xync.sh zookeeper                                                         # 同步 zookeeper 到其它节点
    xcall "${ZOOKEEPER_HOME}/bin/zkServer.sh start"                           # 分别在 slaver1、slaver2、slaver3 执行 
    
    # 查看启动状态
    xcall "jps -l" 
    xcall "${ZOOKEEPER_HOME}/bin/zkServer.sh status"                           # 在每个节点执行查看
```

<br/>

<br/>

## 9. Kafka 安装配置

### 9.1 下载 kafka-3.2.3 安装包

从 [**阿里云镜像网站**](https://mirrors.aliyun.com/apache/) 下载 **[kafka-3.2.3](https://mirrors.aliyun.com/apache/kafka/3.2.3/kafka_2.12-3.2.3.tgz)** 安装包到本地

### 9.2 解压安装 kafka

```bash
    tar -zxvf kafka_2.12-3.2.3.tgz -C /opt/apache/                             # 解压 压缩包
    mv /opt/apache/kafka_2.12-3.2.3 /opt/apache/kafka                          # 修改目录名称
    mkdir -p /opt/apache/kafka/data/                                           # 创建数据存储目录
    mkdir -p /opt/apache/kafka/logs/                                           # 创建日志目录
    
    # 使用 vim 编辑器修改系统配置文件
    vim /etc/profile                                                           # 或使用： sudo vim /etc/profile 
    
    # 添加如下内容：
        # ===================================== Kafka 3.2.3 ====================================== #
        export KAFKA_HOME=/opt/apache/kafka
        export PATH=${PATH}:${KAFKA_HOME}/bin
        
    # 使系统变量生效
    source /etc/profile                                                        # 或者使用： . /etc/profile 
```

### 9.3 修改配置文件

#### 9.3.1 修改 ${KAFKA_HOME}/config/zookeeper.properties

```properties
    # kafka 的数据在 zookeeper 中存储位置
    dataDir=/opt/apache/zookeeper/data
    
    # zookeeper 的端口号
    clientPort=2181
    
    # disable the per-ip limit on the number of connections since this is a non-production config
    maxClientCnxns=0
    
    # Disable the adminserver by default to avoid port conflicts.
    # Set the port to something non-conflicting if choosing to enable this
    admin.enableServer=false
    # admin.serverPort=808
```

#### 9.3.2 修改 ${KAFKA_HOME}/config/producer.properties

```properties
    bootstrap.servers=slaver1:9092,slaver2:9092,slaver3:9092
    
    # specify the compression codec for all data generated: none, gzip, snappy, lz4, zstd
    compression.type=gzip
```

#### 9.3.3 修改 ${KAFKA_HOME}/config/server.properties

```properties
    ############################# Server Basics #############################
    # 配合 broker 的 id：对于每个 broker.id 来说，必须设置为唯一的整数，且从 0 开始（注意：每台机器的 id 不同）
    broker.id=0
    # 删除 topic 功能
    delete.topic.enable=true
    
    ############################# Socket Server Settings #############################
    # 每个节点需要配置自己的参数
    listeners=PLAINTEXT://slaver*:9092
    advertised.listeners=PLAINTEXT://slaver*:9092
    # listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
    
    num.network.threads=3
    num.io.threads=8
    socket.send.buffer.bytes=102400
    socket.receive.buffer.bytes=102400
    socket.request.max.bytes=104857600
    
    ############################# Log Basics #############################
    # 数据日志文件存储路径（用逗号分隔的目录列表）
    log.dirs=/opt/apache/kafka/data
    num.partitions=3
    num.recovery.threads.per.data.dir=1
    
    ############################# Internal Topic Settings  #############################
    offsets.topic.replication.factor=3
    transaction.state.log.replication.factor=3
    transaction.state.log.min.isr=1
    
    ############################# Log Flush Policy #############################
    # log.flush.interval.messages=10000
    # log.flush.interval.ms=1000
    
    ############################# Log Retention Policy #############################
    log.retention.hours=168
    log.segment.bytes=1073741824
    log.retention.check.interval.ms=300000
    
    ############################# Zookeeper #############################
    # 配置连接 zookeeper 的集群地址（用逗号分隔的目录列表）
    zookeeper.connect=slaver1:2181/kafka,slaver2:2181/kafka,slaver3:2181/kafka
    
    # 连接 zookeeper 超时
    zookeeper.connection.timeout.ms=20000
    
    group.initial.rebalance.delay.ms=0
```

#### 9.3.4 修改 ${KAFKA_HOME}/config/consumer.properties

```properties
    bootstrap.servers=slaver1:9092,slaver2:9092,slaver3:9092
    group.id=test-consumer-group
    # auto.offset.reset=
```

### 9.4 安装 kafka 的可视化工具 efak 

#### 9.4.1 下载 efak-3.0.1 安装包

从 [**kafka-eagle 官网**](http://www.kafka-eagle.org/) 找到下载按钮，并 **[点击按钮](https://github.com/smartloli/kafka-eagle-bin/blob/master/efak-web-3.0.2-bin.tar.gz)** 下载安装包到本地

#### 9.4.2 解压安装 efak

```bash
    tar -zxvf kafka-eagle-bin-3.0.1.tgz                                        # 解压 压缩包
    cd kafka_2.12-3.2.3/                                                       # 进入到解压路径
    tar -zxvf efak-web-3.0.1-bin.tar.gz -C ${KAFKA_HOME}/                      # 解压 压缩包
    mv ${KAFKA_HOME}/efak-web-3.0.1 ${KAFKA_HOME}/efak                         # 修改目录名称
    
    # 使用 vim 编辑器修改系统配置文件
    vim /etc/profile                                                           # 或使用： sudo vim /etc/profile 
    
    # 添加如下内容：
        # ===================================== efak 3.0.1 ====================================== #
        export KE_HOME=/opt/apache/kafka/efak
        export PATH=${PATH}:${KE_HOME}/bin
            
    # 使系统变量生效
    source /etc/profile                                                        # 或者使用： . /etc/profile
    
    vim ${ZOOKEEPER_HOME}/bin/zkServer.sh                                      # 修改 Zookeeper 脚本，用于支持 3.5+ 版本
        ZOOMAIN="-Dzookeeper.4lw.commands.whitelist=* ${ZOOMAIN}"              # 在 if [ "x$SERVER_JVMFLAGS" != "x" ] 之前，大约 74 行添加
        
    vim ${KAFKA_HOME}/bin/kafka-run-class.sh                                   # 修改 Kafka 脚本，用于支持 JMX
        JMX_PORT=9988                                                          # 在注释后，脚本开始前添加
```

### 9.4.2 创建 efak 的 mysql 数据库

```mysql
    mycli -h master -P 3306 -u root -p 111111 -D mysql                         # 使用修改后的密码进行登录
    create database if not exists ke;                                          # 创建 efak 数据库
    grant all privileges on ke.* to 'issac'@'%';                               # 将数据库 ke 的所有授权给用户 issac
    flush privileges;                                                          # 刷新权限
```


#### 9.4.3 修改配置文件 ${KE_HOME}/conf/system-config.properties

```properties
    cluster1.zk.list=slaver1:2181/kafka,slaver2:2181/kafka,slaver3:2181/kafka  # 7 行
    efak.webui.port=8048                                                       # 31 行
    efak.worknode.port=8085                                                    # 39 行
    cluster1.efak.offset.storage=kafka                                         # 54 行
    
    efak.distributed.enable=true                                               # 启用分布式模式
    efak.cluster.mode.status=master                                            # 在master节点上设置角色为 master，其他节点设置为 slave
    efak.worknode.master.host=master                                           # 设置 master 节点的主机地址
    efak.worknode.port=8085                                                    # 设置一个可用的端口供 WorkNodeServer 使用
    
    # 元数据存储路径（125-128 行）
    efak.driver=com.mysql.cj.jdbc.Driver
    efak.url=jdbc:mysql://master:3306/ke?useUnicode=true&characterEncoding=UTF-8&createDatabaseIfNotExist=true&allowPublicKeyRetrieval=true&useSSL=false&zeroDateTimeBehavior=convertToNull
    efak.username=issac
    efak.password=111111
```

#### 9.4.4 修改配置文件 ${KE_HOME}/conf/works

```bash
    echo "slaver1" >> ${KE_HOME}/conf/works 
    echo "slaver2" >> ${KE_HOME}/conf/works 
    echo "slaver3" >> ${KE_HOME}/conf/works 
```

### 9.5 编写 kafka 启停和 kafka 集群启停脚本： ${KAFKA_HOME}/bin/kafka.sh

```bash
    xync.sh kafka                                                              # 同步 kafka 到其它节点
    
    xcall "${KAFKA_HOME}/bin/kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties > /dev/null 2>&1 &"  # 每个节点单独启动 
    ${KE_HOME}/bin/ke.sh cluster start                                         # 启动 EFAK
    
    xcall "jps -l"                                                             # 查看 kafka 启动的 jvm 进程
    http://master:8048/                                                        # EFAK UI
```


### 9.6 kafka 测试

```bash
    # 查看当前服务器中的所有 topic
    ${KAFKA_HOME}/bin/kafka-topics.sh --bootstrap-server slaver1:9092,slaver2:9092,slaver3:9092 --list
    
    # 创建 topic
    ${KAFKA_HOME}/bin/kafka-topics.sh --bootstrap-server slaver1:9092,slaver2:9092,slaver3:9092 --create --topic test --replication-factor 3 --partitions 3
    
    # 发送消息
    ${KAFKA_HOME}/bin/kafka-console-producer.sh --broker-list slaver1:9092,slaver2:9092,slaver3:9092 --topic test
    
    # 1.5 消费消息
    ${KAFKA_HOME}/bin/kafka-console-consumer.sh --bootstrap-server slaver1:9092,slaver2:9092,slaver3:9092 --from-beginning --topic test
```

<br/>

<br/>

## 10. Hive 安装配置

### 10.1 编译 Hive（hive-3.1.3 和 hadoop-3.2.4、spark-3.2.3 在兼容性上存在问题，需要修改源码重新编译）

```bash
    # 下载源码，并编译
    git clone https://github.com/apache/hive.git                               # clone 源码
    cd hive || exit                                                            # 进入解压路

    # 切换分支
    git branch                                                                 # 查看本地分支
    git branch -r                                                              # 查看远程分支，-r 表示 remote
    git branch -a                                                              # 查看所有分支
    git checkout rel/release-3.1.3                                             # 切换到 3.1.3 分支
    
    mvn clean -DskipTests package -Pdist                                       # 跳过测试，对 hive 进行编译打包
        
    git apply --check ./hive.patch                                             # 检查 patch 是否可用：https://github.com/lihuashiyu/bigdata-deploy/blob/main/patch/hive.patch
    git apply ./hive.patch                                                     # 应用补丁，不包含 commit 内容
    git am ./hive.patch                                                        # 应用补丁，包含 commit 内容
    
    mvn clean -DskipTests package -Pdist                                       # 跳过测试，对 hive 进行编译打包
```

### 10.2 解压安装

```bash
    cd packaging/target || exit                                                # 进入编译后的打包路径
    tar -zxvf apache-hive-3.1.3-bin.tar.gz -C /opt/apache/                     # 解压编译后的压缩包
    mv /opt/apache/apache-hive-3.1.3-bin /opt/apache/hive                      # 修改目录名称
    mkdir -p /opt/apache/hive/logs/                                            # 创建日志目录
    
    # 使用 vim 编辑器修改系统配置文件
    vim /etc/profile                                                           # 或使用： sudo vim /etc/profile 
    
    # 添加如下内容：
        # ===================================== Hive 3.1.3 ====================================== #
        export HIVE_HOME=/opt/apache/hive
        export PATH=${PATH}:${HIVE_HOME}/bin
        
    # 使系统变量生效
    source /etc/profile                                                        # 或者使用： . /etc/profile 
```

### 10.3 修改配置文件

#### 10.3.1 创建配置文件

```bash
    cd /opt/apache/hive || exit                                                # 切换到 hive 安装目录
    touch ${HIVE_HOME}/conf/hive-env.sh                                        # hive 环境参数配置
    touch ${HIVE_HOME}/conf/hive-site.xml                                      # hive 主要配置文件
    touch ${HIVE_HOME}/conf/beeline-site.xml                                   # beeline 客户端配置文件
    mv ${HIVE_HOME}/conf/hive-log4j2.properties.template ${HIVE_HOME}/conf/hive-log4j2.properties
    
    ${HADOOP_HOME}/bin/hadoop fs -mkdir -p /hive                               # 创建 HDFS 上 Hive 的根目录
    ${HADOOP_HOME}/bin/hadoop fs -mkdir -p /hive/data                          # 创建 HDFS 上 Hive 的 数据存储 目录
    ${HADOOP_HOME}/bin/hadoop fs -mkdir -p /hive/tmp                           # 创建 HDFS 上 Hive 的 临时存储 目录
    ${HADOOP_HOME}/bin/hadoop fs -mkdir -p /hive/logs                          # 创建 HDFS 上 Hive 的 日志存储 目录
    
    ${HADOOP_HOME}/bin/hadoop fs -chmod -R 777 /hive/data                      # 修改 Hive 的 数据存储 目录权限
    ${HADOOP_HOME}/bin/hadoop fs -chmod -R 777 /hive/tmp                       # 修改 Hive 的 临时存储 目录权限
    ${HADOOP_HOME}/bin/hadoop fs -chmod -R 777 /hive/logs                      # 修改 Hive 的 日志存储 目录权限
```

#### 10.3.2 修改 ${HIVE_HOME}/conf/hive-env.sh

```bash
    export HADOOP_HEAPSIZE=4096
    
    # Hadoop 安装路径
    export HADOOP_HOME=/opt/apache/hadoop
    
    # Hive 配置文件路径
    export HIVE_CONF_DIR=/opt/apache/hive/conf
    
    # Hive jar 包路径
    export HIVE_AUX_JARS_PATH=/opt/apache/hive/lib
```

### 10.3.3 修改 ${HIVE_HOME}/conf/hive-site.xml

```xml
    <?xml version="1.0" encoding="UTF-8" standalone="no"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
        <!-- 记录 Hive 中的元数据信息在 mysql 中 -->
        <property>
            <name>javax.jdo.option.ConnectionURL</name>
            <value>jdbc:mysql://master:3306/hive?serverTimezone=UTC&amp;createDatabaseIfNotExist=true&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;allowPublicKeyRetrieval=true</value>
            <description>连接数据库用户名称</description>
        </property>
        <!-- jdbc mysql驱动 -->
        <property>
            <name>javax.jdo.option.ConnectionDriverName</name>
            <value>com.mysql.cj.jdbc.Driver</value>
            <description>连接数据库驱动</description>
        </property>
        <!-- mysql 的用户名和密码 -->
        <property>
            <name>javax.jdo.option.ConnectionUserName</name>
            <value>issac</value>
            <description>连接数据库用户名称</description>
        </property>
        <property>
            <name>javax.jdo.option.ConnectionPassword</name>
            <value>111111</value>
            <description>连接数据库用户密码</description>
        </property>
        
        <!-- Hive 元数据存储版本的验证 -->
        <property>
            <name>hive.metastore.schema.verification</name>
            <value>false</value>
        </property>
        
        <!-- 元数据读取不到 -->
        <property>
            <name>metastore.storage.schema.reader.impl</name>
            <value>org.apache.hadoop.hive.metastore.SerDeStorageSchemaReader</value>
        </property>
         <!-- 元数据存储授权 -->
        <property>
            <name>hive.metastore.event.db.notification.api.auth</name>
            <value>false</value>
        </property>
        
        <!-- 自动创建相关数据 -->
        <property>
            <name>datanucleus.fixedDatastore</name>
            <value>false</value>
        </property>
        <property>
            <name>datanucleus.readOnlyDatastore</name>
            <value>false</value>
        </property>
        <property>
            <name>datanucleus.schema.autoCreateAll</name>
            <value>true</value>
        </property>
        <property>
            <name>datanucleus.autoCreateSchema</name>
            <value>true</value>
        </property>
        <property>
            <name>datanucleus.autoCreateTables</name>
            <value>true</value>
        </property>
        <property>
            <name>datanucleus.autoCreateColumns</name>
            <value>true</value>
        </property>
        <property>
            <name>hive.metastore.local</name>
            <value>true</value>
        </property>
        <!-- 显示表的列名 -->
        <property>
            <name>hive.cli.print.header</name>
            <value>true</value>
            <description>客户端显示当前查询表的头信息</description>
        </property>
        <!-- 显示数据库名称 -->
        <property>
            <name>hive.cli.print.current.db</name>
            <value>true</value>
            <description>客户端显示当前数据库名称信息</description>
        </property>
        <!-- hdfs 位置 -->
        <property>
            <name>hive.metastore.warehouse.dir</name>
            <value>/hive/data</value>
            <description>hdfs 上 hive 数据存放位置</description>
        </property>
        
        <!-- Hive 作业的 HDFS 根目录位置 -->
        <property>
            <name>hive.exec.scratchdir</name>
            <value>/hive/tmp</value>
        </property>
        
        <!-- Hive 作业的 HDFS 根目录创建写权限 -->
        <property>
            <name>hive.scratch.dir.permission</name>
            <value>777</value>
        </property>
        
        <!-- HDFS 日志目录 -->
        <property>
            <name>hive.querylog.location</name>
            <value>/hive/logs</value>
        </property>
        
        <!-- 设置 主节点元数据 metastore 服务的节点信息 -->
        <property>
            <name>hive.metastore.uris</name>
            <value>thrift://master:9083</value>
        </property>
        
        <!-- 客户端远程连接的端口 -->
        <property>
            <name>hive.server2.thrift.port</name>
            <value>10000</value>
        </property>
        <property>
            <name>hive.server2.thrift.bind.host</name>
            <value>0.0.0.0</value>
        </property>
        <property>
            <name>hive.server2.webui.host</name>
            <value>0.0.0.0</value>
        </property>
        
        <!-- hive 服务的页面的端口 -->
        <property>
            <name>hive.server2.webui.port</name>
            <value>10002</value>
        </property>
        
        <property> 
            <name>hive.server2.long.polling.timeout</name>
            <value>5000</value>
        </property>
        
        <property>
            <name>hive.server2.enable.doAs</name>
            <value>true</value>
        </property>
        
        <property>
            <name>datanucleus.autoCreateSchema</name>
            <value>false</value>
        </property>
        
        <property>
            <name>datanucleus.fixedDatastore</name>
            <value>true</value>
        </property>
        
        <property>
            <name>hive.server2.thrift.client.user</name>
            <value>issac</value>
            <description>Username to use against thrift client</description>
        </property>
        <property>
            <name>hive.server2.thrift.client.password</name>
            <value>111111</value>
            <description>Password to use against thrift client</description>
        </property>
        
        <!-- Spark 依赖位置（注意：端口号 9000 必须和 namenode 的端口号一致） -->
        <property>
            <name>spark.yarn.jars</name>
            <value>hdfs://master:9000/spark/jars/*</value>
        </property>
        
        <!-- Hive 默认执行引擎 -->
        <property>
            <name>hive.execution.engine</name>
            <value>spark</value>
        </property>
        <property>
            <name>hive.enable.spark.execution.engine</name>
            <value>true</value>
        </property>
        
        <!-- 连接超时问题 -->
        <property>
            <name>hive.spark.client.connect.timeout</name>
            <value>900000</value>
        </property>
        <property>
            <name>hive.spark.client.server.connect.timeout</name>
            <value>900000</value>
        </property>
        <property>
            <name>hive.fetch.task.conversion</name>
            <value>more</value>
            <description>
                0. none    : disable hive.fetch.task.conversion
                1. minimal : SELECT STAR, FILTER on partition columns, LIMIT only
                2. more    : SELECT, FILTER, LIMIT only (support TABLESAMPLE and virtual columns)
            </description>
        </property>
        
        <!-- Hive 默认的文件存储格式 -->
        <!--
        <property>
            <name>hive.default.fileformat</name>
            <value>parquet</value>
        </property>
        <property>
            <name>hive.default.fileformat.managed</name>
            <value>parquet</value>
        </property>
        -->
        
        <!-- Hive 在执行时使用压缩 -->
        <property>
            <name>hive.exec.compress.intermediate</name>
            <value>true</value>
        </property>
        
        <!-- Hive 在执行时的压缩格式 -->
        <property>
            <name>hive.intermediate.compression.codec</name>
            <value>org.apache.hadoop.io.compress.GzipCodec</value>
        </property>
        
        <!-- Hive 在压缩时，按块进行压缩 -->
        <property>
            <name>hive.intermediate.compression.type</name>
            <value>BLOCK</value>
        </property>
        
        <!-- Hive 在执行结束，输出到 HDFS 的时候使用压缩 -->
        <property>
            <name>hive.exec.compress.output</name>
            <value>true</value>
        </property>
    </configuration>
```

### 10.3.4 修改 ${HIVE_HOME}/conf/beeline-site.xml

```xml
    <?xml version="1.0" encoding="UTF-8" standalone="no"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
        <property>
            <name>beeline.hs2.jdbc.url.tcpUrl</name>
            <value>jdbc:hive2://master:10000/default;user=issac;password=111111</value>
        </property>
        <property>
            <name>beeline.hs2.jdbc.url.httpUrl</name>
            <value>jdbc:hive2://master:10000/default;user=issac;password=111111;transportMode=http;httpPath=cliservice</value>
        </property>
        <property>
            <name>beeline.hs2.jdbc.url.default</name>
            <value>tcpUrl</value>
        </property>
    </configuration>
```

### 10.3.5 修改 ${HIVE_HOME}/conf/hive-log4j2.properties

```properties
    property.hive.log.dir = /opt/apache/hive/logs                              # 修改日志存储路径
```

### 10.3.6 复制 ${HIVE_HOME}/conf/hive-site.xml、${SPARK_HOME}/conf/spark-defaults.conf

```bash
    cp ${HIVE_HOME}/conf/hive-site.xml ${SPARK_HOME}/conf/                     # 复制 hive 配置到 spark 配置目录，用于搭建 hive on spark 
    cp ${SPARK_HOME}/conf/spark-defaults.conf ${HIVE_HOME}/conf/               # 复制 spark 配置到 hive 配置目录，用于搭建 hive on spark
```

### 10.4 初始化元数据，并启动

```bash
    cp mysql-connector-java-8.0.31.jar ${HIVE_HOME}/lib/
    
    /opt/mysql/bin/mysql.sh start                                              # 启动数据库
    mycli -h master -P 3306 -u root -p 111111 -D mysql                         # 连接数据库
    
    create database if not exists hive;                                        # 创建 hive  数据库
    grant all privileges on hive.*  to 'issac'@'%';                            # 将数据库 hive 的所有权限给用户 issac
    
    ${HIVE_HOME}/bin/schematool -dbType mysql -initSchema -verbose             # 初始化元数据
```

#### 10.5 解决 hive 中文乱码

```mysql
    -- 登录 mysql，切换到 hive 数据库
    use hive;
    
    -- 修改字段注释字符集
    alter table columns_v2       modify column comment      varchar(2048)  character set utf8mb4;
    
    -- 修改表注释字符集
    alter table table_params     modify column param_value  varchar(4096)  character set utf8mb4;
    
    -- 修改分区参数，支持分区建用中文表示
    alter table partition_params modify column param_value  varchar(4096)  character set utf8mb4;
    alter table partition_keys   modify column pkey_comment varchar(4096)  character set utf8mb4;
    
    -- 修改索引名注释，支持中文表示
    alter table index_params     modify column param_value  varchar(4096)  character set utf8mb4;
    
    -- 修改视图，支持视图中文
    alter table tbls modify column view_expanded_text       mediumtext     character set utf8mb4;
    alter table tbls modify column view_original_text       mediumtext     character set utf8mb4;
    
    -- 刷新权限
    flush privileges;
```

### 10.6 同步 hive 安装路径，分发到其他节点 

```bash
    xync.sh hive                                                               # 同步 hive 到其它节点
        
    # 单个服务一次启动，分别启动 metastore 和 hiveserver2 
    nohup ${HIVE_HOME}/bin/hive --service metastore >> ${HIVE_HOME}/logs/${LOG_FILE} 2>&1 &
    nohup ${HIVE_HOME}/bin/hiveserver2              >> ${HIVE_HOME}/logs/${LOG_FILE} 2>&1 &
    
    # 查看 hive 启动状态
    jps -l 
    http://master:10002/
```

### 10.7 测试 Hive

```mysql
    -- 使用 datagrip 连接上 hive 
    
    show databases;                                                            -- 查看所有数据库
    create database if not exists test;                                        -- 创建 test 数据库
    use test;                                                                  -- 切换到 test 数据库
    create table if not exists student                                         -- 创建 test 数据库
    (
        id     int           comment '主键 ID',
        name   varchar(64)   comment '姓名',
        age    int           comment '年龄',
        gender int           comment '性别：-1，未知；0，女；1：男',
        hight  float         comment '身高：厘米',
        wight  float         comment '体重：千克',
        email  varchar(128)  comment '电子邮件',
        remark varchar(1024) comment '备注'
    ) comment '学生测试表';

    set mapreduce.map.java.opts='-Xmx4096m';                                   -- 设置 map 堆内存
    set mapreduce.reduce.java.opts='-Xms4096m';                                -- 设置 reduce 堆内存
    
    -- 测试 mr 引擎
    set hive.execution.engine=mr;
    insert into student (id, name, age, gender, hight, wight, email, remark) values (1, '张三', 33, 1, 172.1, 48.9, 'zhangsan@qq.com', '学生');
    
    -- 测试 spark 引擎
    set hive.execution.engine=spark;
    insert into student (id, name, age, gender, hight, wight, email, remark) values (2, '李四', 23, 0, 165.1, 53.9, 'lisi@qq.com', '学生');
    insert into student (id, name, age, gender, hight, wight, email, remark) 
        values (3, '王五', 28, 1, 168.3, 52.7, 'wangwu@qq.com', '学生'), 
               (4, '赵六', 22, 0, 161.3, 46.7, 'zhaoliu@qq.com', '教师');
    
    -- 测试执行计划
    explain formatted select * from student;
    select * from student limit 10;
```

<br/>

<br/>

## 11. Flume 安装

### 11.1 Flume-1.11.0 下载

从 [**阿里云镜像网站**](https://mirrors.aliyun.com/apache/) 下载 **[flume-1.11.0](https://mirrors.aliyun.com/apache/flume/1.11.0/apache-flume-1.11.0-bin.tar.gz)** 安装包到本地

### 11.2 解压安装 flume

```bash
    tar -zxvf apache-flume-1.11.0-bin.tar.gz -C /opt/apache/                   # 解压 压缩包
    mv /opt/apache/apache-flume-1.11.0-bin /opt/apache/flume                   # 修改目录名称
    mkdir -p /opt/apache/flume/logs/                                           # 创建日志目录
        
    # 使用 vim 编辑器修改系统配置文件
    vim /etc/profile                                                           # 或使用： sudo vim /etc/profile 
    
    # 添加如下内容：
        # ===================================== flume 1.11.0 ====================================== #
        export FLUME_HOME=/opt/apache/flume
        export PATH=${PATH}:${FLUME_HOME}/bin
            
    # 使系统变量生效
    source /etc/profile                                                        # 或者使用： . /etc/profile 
```

### 11.3 配置文件修改

#### 11.3.1 创建 ${FLUME_HOME}/conf/flume-env.sh 

```bash
    # 添加如下内容：
    export JAVA_HOME=/opt/java/jdk-08
    export JAVA_OPTS="-Xms256m -Xmx512m -Dcom.sun.management.jmxremote"
    # FLUME_CLASSPATH=""
```

#### 11.3.2 创建 ${FLUME_HOME}/bin/flume-ng

```bash
    # 修改 229 行（若在 ${FLUME_HOME}/conf/flume-env.sh 修改过该参数，此处需忽略）
    JAVA_OPTS="-Xms256m -Xmx512m"
```

#### 11.3.3 修改 ${FLUME_HOME}/bin/log4j2.xml

```xml
    <!-- 修改 21 行日志存储目录 -->
    <Property name="LOG_DIR">/opt/apache/flume/logs</Property>
```

#### 11.3.4 配置与 hadoop 兼容性问题

```bash
    # 解决与 hadoop 的 guava 依赖
    rm ${FLUME_HOME}/lib/guava-11.0.2.jar                                      # 删除 flume 旧版本的 guava
    cp -fr ${HADOOP_HOME}/share/hadoop/common/lib/guava-27.0-jre.jar ${FLUME_HOME}/lib/  # 和 hadoop 保持一致
    
    # 复制 hadoop 的 jar 用于支持 HDFS 的读写（flume-1.9.0 之后版本无需复制 jar）
    cp -fr ${HADOOP_HOME}/share/hadoop/common/*.jar     ${FLUME_HOME}/lib/
    cp -fr ${HADOOP_HOME}/share/hadoop/common/lib/*.jar ${FLUME_HOME}/lib/
    cp -fr ${HADOOP_HOME}/share/hadoop/hdfs/*.jar       ${FLUME_HOME}/lib/
    cp -fr ${HADOOP_HOME}/share/hadoop/hdfs/lib/*.jar   ${FLUME_HOME}/lib/
    
    # 复制 hadoop 的 配置文件 用于支持 HDFS 的读写（使用时，可在配置文件中指定，非必须配置）
    cp -fr ${HADOOP_HOME}/etc/hadoop/core-site.xml      ${FLUME_HOME}/conf/
    cp -fr ${HADOOP_HOME}/etc/hadoop/hdfs-site.xml      ${FLUME_HOME}/conf/
```

#### 11.3.5 创建 ${FLUME_HOME}/conf/flume-conf.properties

```properties
    # 添加如下内容：
    ############################## agent 中各组件的名字 ##############################
    ## agent 中的 source 组件
    a1.sources = r1
    ## agent 中的下沉组件 sink
    a1.sinks = k1
    ## agent 内部的数据传输通道 channel，用于从 source 将数据传递到 sink
    a1.channels = c1
     
    ########################### 描述和配置 source 组件：r1 ############################
    ## netcat 用于监听一个端口的
    a1.sources.r1.type = netcat
    ## 配置的绑定地址,这个机器的 hostname 是 master，所以下面也可以配置成 master
    a1.sources.r1.bind = master
    ## 配置的绑定端口
    a1.sources.r1.port = 44444
     
    # 描述和配置sink组件：k1
    a1.sinks.k1.type = logger
     
    ######################## 描述和配置 channel 组件，此处使用内存 ########################
    ## 缓存到内存中，如果是文件，可以使用 file 类型
    a1.channels.c1.type = memory
    ## 使用的空间
    a1.channels.c1.capacity = 1000
    ## 事务使用的空间
    a1.channels.c1.transactionCapacity = 100
    
    ########################## source channel sink之间的连接关系 ##########################
    a1.sources.r1.channels = c1
    a1.sinks.k1.channel = c1
```

### 11.4 测试

```bash
    sudo yum install -y telnet                                                 # 安装 telnet
    
    ${FLUME_HOME}/bin/flume-ng version                                         # 查看 flume 版本号
    
    # 启动 flume 进行测试
    ${FLUME_HOME}/bin/flume-ng agent -c conf -f ${FLUME_HOME}/conf/flume-conf.properties -n a1 -Dflume.root.logger=INFO,console
    
    telnet master 44444                                                        # 新建终端，并启动 telnet，然后使用键盘进行输入
    less ${FLUME_HOME}/logs/flume.log                                          # 查看日志中是否输出相关信息
    
    ~/shell/xync.sh /opt/apache/flume                                          # 测试完毕，并成功后，进行分发
```

<br/>

## 12. MaxWell 安装

### 12.1 MaxWell 下载
  从 [**Mysql 官网**](https://www.github.com/) 下载 **[maxwell-1.39.5](https://github.com/zendesk/maxwell/releases/download/v1.39.5/maxwell-1.39.5.tar.gz)** 到本地

### 12.2 解压安装
```bash
    tar -zxvf maxwell-1.39.5.tar.gz -C /opt/githud/                            # 解压下载的 maxwell-1.39.5 压缩包
    mv /opt/githud/maxwell-1.39.5/ /opt/githud/maxwell/                        # 修改目录名称
    
    # 修改 maxwell 使用的 jdk 版本
    JAVA_HOME=/opt/java/jdk-11/bin/java                                        # 在 maxwell/bin/maxwell           的 91 行添加
    JAVA_HOME=/opt/java/jdk-11/bin/java                                        # 在 maxwell/bin/maxwell-benchmark 的 92 行添加
    JAVA_HOME=/opt/java/jdk-11/bin/java                                        # 在 maxwell/bin/maxwell-bootstrap 的 15 行添加
    JAVA_HOME=/opt/java/jdk-11/bin/java                                        # 在 maxwell/bin/maxwell-large-txt 的 15 行添加
```

<br/>

### 13. DataX 安装


### 13.1 DataX 下载
从 [**GitHub**](https://github.com/alibaba/DataX) 提供的下载地址，将 **[maxwell-1.39.5](https://datax-opensource.oss-cn-hangzhou.aliyuncs.com/202210/datax.tar.gz)** 下载到本地


### 13.2 解压安装
```bash
    tar -zxvf datax.tar.gz -C /opt/githud/                                     # 解压下载的 datax-202210 压缩包
    
    # 修改 mysql 的 reader 和 writer 中 mysql 驱动的版本
    rm /opt/githud/datax/plugin/reader/mysqlreader/libs/mysql-connector-java-5.1.47.jar
    rm /opt/githud/datax/plugin/reader/mysqlwriter/libs/mysql-connector-java-5.1.47.jar
    
    cp mysql-connector-java-8.0.31.jar /opt/githud/datax/plugin/reader/mysqlreader/libs/
    cp mysql-connector-java-8.0.31.jar /opt/githud/datax/plugin/reader/mysqlwriter/libs/
```

